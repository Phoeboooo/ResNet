{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zoe0fL-YkrAG",
    "outputId": "a61842d1-70c6-4bec-a2d9-40d6fd0d74c0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Activation, merge, Dense, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization, add, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J4t2CfT8p2aA"
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Xj428clkv_q"
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "\n",
    "n_classes = 10\n",
    "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5763
    },
    "colab_type": "code",
    "id": "mHjxpKxEprpH",
    "outputId": "c5badd65-5778-4691-e517-640657dc5c30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 32)   4736        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 32)   128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 32)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 16, 16, 8)    264         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16, 16, 8)    32          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 16, 16, 8)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 16, 16, 8)    584         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 16, 16, 8)    32          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 16, 16, 8)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 16, 32)   288         activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 32)   1056        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 16, 16, 32)   128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 16, 16, 32)   0           conv2d_5[0][0]                   \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 12)   396         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 12)   48          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16, 16, 12)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 12)   1308        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 12)   48          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 12)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 48)   624         activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 48)   1584        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 48)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 16, 16, 48)   0           conv2d_9[0][0]                   \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 16)   784         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 16)   64          conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 16, 16)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 16)   2320        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 16)   64          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 16, 16)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 64)   1088        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 64)   3136        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 64)   256         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 16, 16, 64)   0           conv2d_13[0][0]                  \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 20)   1300        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 20)   80          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 20)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 20)   3620        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 20)   80          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 20)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 80)   1680        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 80)   5200        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 80)   320         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 80)   0           conv2d_17[0][0]                  \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 24)   1944        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 24)   96          conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 24)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 24)   5208        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 24)   96          conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 24)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 96)   2400        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 96)   7776        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 96)   384         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 96)   0           conv2d_21[0][0]                  \n",
      "                                                                 batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 28)   2716        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 28)   112         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 28)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 28)   7084        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 28)   112         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 28)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 112)  3248        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 112)  10864       add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 112)  448         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 16, 16, 112)  0           conv2d_25[0][0]                  \n",
      "                                                                 batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 16, 32)   3616        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 16, 32)   128         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 32)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 32)   9248        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 16, 16, 32)   128         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 32)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 128)  4224        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 16, 16, 128)  14464       add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 128)  512         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 16, 16, 128)  0           conv2d_29[0][0]                  \n",
      "                                                                 batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 16, 16, 36)   4644        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 36)   144         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 36)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 16, 16, 36)   11700       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 36)   144         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 36)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 16, 16, 144)  5328        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 16, 16, 144)  18576       add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 144)  576         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 16, 16, 144)  0           conv2d_33[0][0]                  \n",
      "                                                                 batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 16, 16, 40)   5800        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 16, 16, 40)   160         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 40)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 16, 16, 40)   14440       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 16, 40)   160         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 40)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 16, 16, 160)  6560        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 16, 16, 160)  23200       add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 160)  640         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 16, 16, 160)  0           conv2d_37[0][0]                  \n",
      "                                                                 batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 160)    0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 8, 8, 44)     7084        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 8, 8, 44)     176         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 8, 8, 44)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 8, 8, 44)     17468       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 8, 8, 44)     176         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 8, 8, 44)     0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 8, 8, 176)    7920        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 8, 8, 176)    28336       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 8, 8, 176)    704         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 8, 8, 176)    0           conv2d_41[0][0]                  \n",
      "                                                                 batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 8, 8, 48)     8496        add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 8, 8, 48)     192         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 8, 8, 48)     0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 8, 8, 48)     20784       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 8, 8, 48)     192         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 8, 8, 48)     0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 8, 8, 192)    9408        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 8, 8, 192)    33984       add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 8, 8, 192)    768         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 8, 8, 192)    0           conv2d_45[0][0]                  \n",
      "                                                                 batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 8, 8, 52)     10036       add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 8, 8, 52)     208         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 8, 8, 52)     0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 8, 8, 52)     24388       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 8, 8, 52)     208         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 8, 8, 52)     0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 8, 8, 208)    11024       activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 8, 8, 208)    40144       add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 8, 8, 208)    832         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 8, 8, 208)    0           conv2d_49[0][0]                  \n",
      "                                                                 batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 8, 8, 56)     11704       add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 8, 8, 56)     224         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 8, 8, 56)     0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 8, 8, 56)     28280       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 8, 8, 56)     224         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 8, 8, 56)     0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 8, 8, 224)    12768       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 8, 8, 224)    46816       add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 8, 8, 224)    896         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 8, 8, 224)    0           conv2d_53[0][0]                  \n",
      "                                                                 batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 8, 8, 60)     13500       add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 8, 8, 60)     240         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 8, 8, 60)     0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 8, 8, 60)     32460       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 8, 8, 60)     240         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 8, 8, 60)     0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 8, 8, 240)    14640       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 8, 8, 240)    54000       add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 8, 8, 240)    960         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 8, 8, 240)    0           conv2d_57[0][0]                  \n",
      "                                                                 batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 8, 8, 64)     15424       add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 8, 8, 64)     256         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 8, 8, 64)     0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 8, 8, 64)     36928       activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 8, 8, 64)     256         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 8, 8, 64)     0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 8, 8, 256)    16640       activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 8, 8, 256)    61696       add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 8, 8, 256)    1024        conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 8, 8, 256)    0           conv2d_61[0][0]                  \n",
      "                                                                 batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 256)          0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           2570        global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 772,594\n",
      "Trainable params: 766,050\n",
      "Non-trainable params: 6,544\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def _shortcut(inputs, residual):\n",
    "    n_filters = residual._keras_shape[3]\n",
    "    shortcut = Convolution2D(n_filters, (1,1), strides=(1,1), padding='valid')(inputs)\n",
    "  \n",
    "    return add([shortcut, residual])\n",
    "\n",
    "\n",
    "\n",
    "def _resblock(n_filters1, n_filters2, strides=(1,1)):\n",
    "    def f(input):\n",
    "        x = Convolution2D(n_filters1, (1,1), strides=strides,\n",
    "                                      kernel_initializer='he_normal', padding='same')(input)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Convolution2D(n_filters1, (3,3), strides=strides,\n",
    "                                      kernel_initializer='he_normal', padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Convolution2D(n_filters2, (1,1), strides=strides,\n",
    "                                      kernel_initializer='he_normal', padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "   \n",
    "        return _shortcut(input, x)\n",
    "    \n",
    "    return f\n",
    "\n",
    "\n",
    "def resnet():\n",
    "    inputs = Input(shape=(32, 32, 3))\n",
    "  \n",
    "    x = Convolution2D(32, (7,7), strides=(1,1),\n",
    "                    kernel_initializer='he_normal', padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2,2), padding='same')(x)\n",
    "  \n",
    " \n",
    "  \n",
    "    x = _resblock(n_filters1=8, n_filters2=32)(x)\n",
    "    x = _resblock(n_filters1=12, n_filters2=48)(x)\n",
    "    x = _resblock(n_filters1=16, n_filters2=64)(x)\n",
    "    x = _resblock(n_filters1=20, n_filters2=80)(x)\n",
    "    x = _resblock(n_filters1=24, n_filters2=96)(x)\n",
    "    x = _resblock(n_filters1=28, n_filters2=112)(x)\n",
    "    x = _resblock(n_filters1=32, n_filters2=128)(x)\n",
    "    x = _resblock(n_filters1=36, n_filters2=144)(x)\n",
    "    x = _resblock(n_filters1=40, n_filters2=160)(x)\n",
    "    x = MaxPooling2D(strides=(2,2))(x) \n",
    "    x = _resblock(n_filters1=44, n_filters2=176)(x)\n",
    "    x = _resblock(n_filters1=48, n_filters2=192)(x)\n",
    "    x = _resblock(n_filters1=52, n_filters2=208)(x) \n",
    "    x = _resblock(n_filters1=56, n_filters2=224)(x)\n",
    "    x = _resblock(n_filters1=60, n_filters2=240)(x)\n",
    "    x = _resblock(n_filters1=64, n_filters2=256)(x) \n",
    "\n",
    "  \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(10, kernel_initializer='he_normal', activation='softmax')(x)\n",
    "  \n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model\n",
    "\n",
    "model = resnet()\n",
    "\n",
    "adam = Adam()\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2074
    },
    "colab_type": "code",
    "id": "lODv3Bp5tS48",
    "outputId": "20bea336-638b-41c2-d0c3-6b994cf410c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/60\n",
      "40000/40000 [==============================] - 122s 3ms/step - loss: 1.5614 - acc: 0.4512 - val_loss: 1.5788 - val_acc: 0.4619\n",
      "Epoch 2/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 1.2226 - acc: 0.5624 - val_loss: 1.3885 - val_acc: 0.5488\n",
      "Epoch 3/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 1.0699 - acc: 0.6214 - val_loss: 1.2827 - val_acc: 0.5484\n",
      "Epoch 4/60\n",
      "40000/40000 [==============================] - 109s 3ms/step - loss: 0.9608 - acc: 0.6606 - val_loss: 1.3223 - val_acc: 0.5601\n",
      "Epoch 5/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.8816 - acc: 0.6931 - val_loss: 1.6805 - val_acc: 0.5463\n",
      "Epoch 6/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.8281 - acc: 0.7103 - val_loss: 1.1579 - val_acc: 0.6088\n",
      "Epoch 7/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.7755 - acc: 0.7303 - val_loss: 1.2183 - val_acc: 0.5726\n",
      "Epoch 8/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.7404 - acc: 0.7415 - val_loss: 1.0939 - val_acc: 0.6495\n",
      "Epoch 9/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.7025 - acc: 0.7536 - val_loss: 0.8287 - val_acc: 0.7090\n",
      "Epoch 10/60\n",
      "40000/40000 [==============================] - 109s 3ms/step - loss: 0.6707 - acc: 0.7658 - val_loss: 0.9066 - val_acc: 0.6808\n",
      "Epoch 11/60\n",
      "40000/40000 [==============================] - 109s 3ms/step - loss: 0.6422 - acc: 0.7774 - val_loss: 0.8752 - val_acc: 0.7055\n",
      "Epoch 12/60\n",
      "40000/40000 [==============================] - 109s 3ms/step - loss: 0.6139 - acc: 0.7871 - val_loss: 0.8114 - val_acc: 0.7249\n",
      "Epoch 13/60\n",
      "40000/40000 [==============================] - 109s 3ms/step - loss: 0.5954 - acc: 0.7939 - val_loss: 0.7600 - val_acc: 0.7374\n",
      "Epoch 14/60\n",
      "40000/40000 [==============================] - 109s 3ms/step - loss: 0.5548 - acc: 0.8060 - val_loss: 0.9247 - val_acc: 0.7085\n",
      "Epoch 15/60\n",
      "40000/40000 [==============================] - 109s 3ms/step - loss: 0.5501 - acc: 0.8086 - val_loss: 0.8319 - val_acc: 0.7322\n",
      "Epoch 16/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.5249 - acc: 0.8171 - val_loss: 0.8768 - val_acc: 0.7280\n",
      "Epoch 17/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.5103 - acc: 0.8237 - val_loss: 0.8899 - val_acc: 0.7062\n",
      "Epoch 18/60\n",
      "40000/40000 [==============================] - 109s 3ms/step - loss: 0.4934 - acc: 0.8280 - val_loss: 0.8080 - val_acc: 0.7331\n",
      "Epoch 19/60\n",
      "40000/40000 [==============================] - 109s 3ms/step - loss: 0.4789 - acc: 0.8325 - val_loss: 0.8154 - val_acc: 0.7325\n",
      "Epoch 20/60\n",
      "40000/40000 [==============================] - 109s 3ms/step - loss: 0.4618 - acc: 0.8382 - val_loss: 0.6958 - val_acc: 0.7624\n",
      "Epoch 21/60\n",
      "40000/40000 [==============================] - 109s 3ms/step - loss: 0.4457 - acc: 0.8443 - val_loss: 0.7863 - val_acc: 0.7484\n",
      "Epoch 22/60\n",
      "40000/40000 [==============================] - 109s 3ms/step - loss: 0.4324 - acc: 0.8488 - val_loss: 0.7963 - val_acc: 0.7455\n",
      "Epoch 23/60\n",
      "40000/40000 [==============================] - 109s 3ms/step - loss: 0.4210 - acc: 0.8533 - val_loss: 0.7414 - val_acc: 0.7525\n",
      "Epoch 24/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.4064 - acc: 0.8573 - val_loss: 0.9551 - val_acc: 0.7171\n",
      "Epoch 25/60\n",
      "40000/40000 [==============================] - 109s 3ms/step - loss: 0.3879 - acc: 0.8658 - val_loss: 0.8598 - val_acc: 0.7383\n",
      "Epoch 26/60\n",
      "40000/40000 [==============================] - 109s 3ms/step - loss: 0.3814 - acc: 0.8658 - val_loss: 0.8928 - val_acc: 0.7276\n",
      "Epoch 27/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.3773 - acc: 0.8672 - val_loss: 0.8827 - val_acc: 0.7444\n",
      "Epoch 28/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.3551 - acc: 0.8742 - val_loss: 0.8235 - val_acc: 0.7621\n",
      "Epoch 29/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.3541 - acc: 0.8751 - val_loss: 0.8645 - val_acc: 0.7408\n",
      "Epoch 30/60\n",
      "40000/40000 [==============================] - 109s 3ms/step - loss: 0.3389 - acc: 0.8801 - val_loss: 0.8503 - val_acc: 0.7324\n",
      "Epoch 31/60\n",
      "40000/40000 [==============================] - 117s 3ms/step - loss: 0.3314 - acc: 0.8836 - val_loss: 0.7224 - val_acc: 0.7861\n",
      "Epoch 32/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.3222 - acc: 0.8862 - val_loss: 0.8808 - val_acc: 0.7296\n",
      "Epoch 33/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.3162 - acc: 0.8868 - val_loss: 0.8092 - val_acc: 0.7516\n",
      "Epoch 34/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.3043 - acc: 0.8945 - val_loss: 0.7119 - val_acc: 0.7889\n",
      "Epoch 35/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.2916 - acc: 0.8952 - val_loss: 0.8085 - val_acc: 0.7638\n",
      "Epoch 36/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.2938 - acc: 0.8956 - val_loss: 0.7925 - val_acc: 0.7757\n",
      "Epoch 37/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.2801 - acc: 0.8995 - val_loss: 0.9641 - val_acc: 0.7380\n",
      "Epoch 38/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.2771 - acc: 0.9011 - val_loss: 0.9210 - val_acc: 0.7488\n",
      "Epoch 39/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.2628 - acc: 0.9087 - val_loss: 0.9607 - val_acc: 0.7380\n",
      "Epoch 40/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.2585 - acc: 0.9085 - val_loss: 1.0288 - val_acc: 0.7248\n",
      "Epoch 41/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.2494 - acc: 0.9128 - val_loss: 0.8859 - val_acc: 0.7571\n",
      "Epoch 42/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.2468 - acc: 0.9147 - val_loss: 1.2186 - val_acc: 0.6868\n",
      "Epoch 43/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.2434 - acc: 0.9139 - val_loss: 0.7717 - val_acc: 0.7870\n",
      "Epoch 44/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.2356 - acc: 0.9152 - val_loss: 0.9856 - val_acc: 0.7418\n",
      "Epoch 45/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.2333 - acc: 0.9182 - val_loss: 0.7753 - val_acc: 0.7810\n",
      "Epoch 46/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.2196 - acc: 0.9228 - val_loss: 0.8002 - val_acc: 0.7819\n",
      "Epoch 47/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.2200 - acc: 0.9227 - val_loss: 1.1807 - val_acc: 0.7013\n",
      "Epoch 48/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.2097 - acc: 0.9245 - val_loss: 0.8893 - val_acc: 0.7708\n",
      "Epoch 49/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.2116 - acc: 0.9242 - val_loss: 1.0542 - val_acc: 0.7424\n",
      "Epoch 50/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.1982 - acc: 0.9290 - val_loss: 0.9371 - val_acc: 0.7657\n",
      "Epoch 51/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.2016 - acc: 0.9281 - val_loss: 0.8334 - val_acc: 0.7709\n",
      "Epoch 52/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.1951 - acc: 0.9299 - val_loss: 1.0004 - val_acc: 0.7512\n",
      "Epoch 53/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.1880 - acc: 0.9335 - val_loss: 1.1949 - val_acc: 0.7233\n",
      "Epoch 54/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.1946 - acc: 0.9313 - val_loss: 1.0192 - val_acc: 0.7401\n",
      "Epoch 55/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.1777 - acc: 0.9375 - val_loss: 0.8403 - val_acc: 0.7812\n",
      "Epoch 56/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.1748 - acc: 0.9367 - val_loss: 0.8443 - val_acc: 0.7806\n",
      "Epoch 57/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.1801 - acc: 0.9371 - val_loss: 0.8037 - val_acc: 0.7928\n",
      "Epoch 58/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.1703 - acc: 0.9396 - val_loss: 0.8513 - val_acc: 0.7853\n",
      "Epoch 59/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.1731 - acc: 0.9370 - val_loss: 1.2282 - val_acc: 0.7122\n",
      "Epoch 60/60\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.1647 - acc: 0.9412 - val_loss: 0.9230 - val_acc: 0.7716\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "epochs = 60\n",
    "\n",
    "\n",
    "h = model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_split=0.2,)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ResNet1 ",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
